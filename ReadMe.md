#This is my first MarkDown.

##简介

这是一个关于[天涯论坛](http://bbs.tianya.cn/list-828-1.shtml)的基于Python(2.7)的Scrapy框架的爬虫，主要的爬虫部分由if-zz编写，我负责的是提供一部分爬虫所需要的Xpath路径，定时器，以及数据库的连接、插入、更新等操作。

##Xpath
* 很多部分都可以直接使用Chrome自带的生成Xpath的功能，很方便。
* （针对于之前写的大成社区的爬虫）部分帖子的html源代码的格式有一定的差异，所以为了对所有的帖子都能爬取其内容，可以在Xpath的语句中使用“|”来多项筛选，这样爬取的数据比较完整。
* 新技能get：使用诸如“@ahref”来获取标签的属性的内容。
* `extract()`部分仍然有些迷惑，在很多网上的教程中都看到过使用这个方法。

##定时器
* 写了两个定时器，一个是每天的固定时间爬取，原理是每隔一定的时间使用`time.time()`获取当前的时间，与提前设定的时间进行比较，针对比较结果选择启动爬虫/继续等待。
* 第二个是现在正在使用的定时器，第一次启动爬虫需要手动运行，然后程序一直处于执行状态，在Scrapy()完成之后Sleep()，接着继续循环执行Scrapy()。并且这里调用了logging库，将爬虫运行时的bug info保存到logs中，以时间戳命名。
* 定时器在begin.py中，是一部分比较乱的代码。【脸黑没人权，连个单独的py文件都不给我。】

*嗯...　这里在调用爬虫的运行函数run()时采用了多进程，我也忘记了为什么当时要这么干... 我现在急着回家前往国王大道！Overwatch~*

##数据库操作
* 调用了MySQLdb的库，非常好用。之前一直觉得用Python连接数据库很麻烦，想想都觉得是很庞大的工程，其实真的到了自己开始动手做的时候，边做边学，也没有那么困难。
* `cursor.execute()`方法就相当于在数据库中直接运行语句，不需要对语句有任何额外的改变。简直是神器。
* 当然要吐槽一下的还是`cursor.execute()`,这在最后Debug的时候，我误以为这个函数返回的就是SEELECT ID中的ID的值，其实返回的是整个SELECT的结果，还需要`self.cursor.fetchone()[0]`来获取单条的数据。
* 在语句`cursor.execute()`后，要使得语句生效，还需要`conn.commit()`来提交事务。
* 之前遇到过一次问题，就是插入语句完成后，没有报错，但是去Mysql中SELECT找不到该条目，但是主键的又在自增。比如我的主键设定的是自增，现在最后表中最后一项的PK是5，讲道理下一跳是6，我用Python插入了一条，SELECT找不到，但是再在mysql中添加表项，PK就成了7.然而我又忘记这是怎么解决的了...

##思考
* 在调试的时候使用了很多笨办法，好多地方仔细看看代码就能找出bug所在，会的方法也很有限，有些地方走了些弯路。
* 直到写到这个ReadMe的末尾，我仍然发现对于这个程序中，有很多的地方我还没有弄的完全清楚，明白，比如上面说的`extract()`，所以这些都还是我需要反省和深究的，多探究，不要很多事情觉得知其然就放下了。
* 在最后写Mysql操作的部分，因为编写任务放到了我身上，所以不得不安装Pyhton2.7，之前一直是3.5，因为怕双版本Pyhton麻烦就没装。还是老毛病，啥事都怕麻烦。

##感谢

* 首先是向大佬低头！感谢if-zz，在1400分黄金无敌保研大师兄的带领下，我们合作完成了这个大项目的初步爬虫部分的工作。有些时候我比较胆怯，或者说总是把任务想象的太难太重，但是有时候一想到有大师兄撑着好像这些事情也没有那么困难。也再次感谢大师兄多次帮我Debug，还有让我请他吃KFC吃烤肠（臭不要脸）。
* 感谢每天跟我们一起来划水的超级无敌麦旋风小明同学。经常等我们俩半天才能去吃饭/回寝室。总觉得三个人走一起笑点低，各种开心乐呵。“很欢乐啊”。
* 实验室的两个师兄都很厉害的样子，感觉都是很勤奋踏实的那种人，也激励着我认真学习。（不好意思划水玩手机）。